{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import cssutils\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "base_link = \"https://www.comics.org\"\n",
    "headers = {'cookie': 'csrftoken=QHJodRDYKJURtwTstbtNgm11Y9CQXpah9bcrpeEQzidXymRdveyB7v40kxX9BBod; _pbjs_userid_consent_data=3524755945110770; SL_G_WPT_TO=tr; SL_GWPT_Show_Hide_tmp=1; SL_wptGlobTipTmp=1; na-unifiedid=%7B%22TDID_LOOKUP%22%3A%22FALSE%22%2C%22TDID_CREATED_AT%22%3A%222022-10-25T16%3A13%3A58%22%7D; __cf_bm=rhAa8ngQuuaZS_oCQmF0SUmhwjb7_UmRg4S.3700sEE-1666716009-0-AR/tYj4CL2rJORh5yxy5tEaYkgOQelY5ZdFtZ7P3TuL4w0i5BmpH0qA3yvu+KqgxDZtcIjZvGL/LRrDQyspWsstClokAEzoLDkm7lJrr+q3CSj1DZvWppNa7FL5Ugcp2uQ==',\n",
    "          'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36 Edg/106.0.1370.52'}\n",
    "marvel_id = 78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_number(publisher_id):\n",
    "    link = f'https://www.comics.org/publisher/{publisher_id}'\n",
    "    req = requests.get(link,  headers=headers)\n",
    "    soup = BeautifulSoup(req.text, 'html.parser')\n",
    "    \n",
    "    page_bar_div = soup.find(\"div\", {\"class\":\"right pagination\"})\n",
    "    page_bar_div_li = page_bar_div.find_all(\"a\", {\"class\": \"btn btn-default btn-sm\"})\n",
    "    \n",
    "    page_number = int(page_bar_div_li[-2]['href'].split(\"=\")[-1])\n",
    "    \n",
    "    return page_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_comic_details(page_number):\n",
    "    datas = []\n",
    "    for idx in range(page_number):\n",
    "        link = f'https://www.comics.org/publisher/78/?sort=year&page={idx+1}'\n",
    "        \n",
    "        req = requests.get(link, headers=headers)\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')\n",
    "        \n",
    "        comic_table = soup.find(\"table\", {\"class\":\"sortable_listing\"})\n",
    "        \n",
    "        #Comic list columns name\n",
    "        columns_name = soup.find(\"thead\").find_all(\"th\")\n",
    "        columns_name = [i.text for i in columns_name] + ['Series Link', 'Covers1 Link', 'Covers2 Link', 'Img']#, 'Color', 'Dimensions', 'Paper Stock', 'Binding', 'Publishing Format', 'Publication Type'\n",
    "        \n",
    "        #Comic list data\n",
    "        data = soup.find(\"tbody\").find_all(\"tr\")\n",
    "        for data_piece in data:\n",
    "            data_info = data_piece.find_all(\"td\")\n",
    "            data_info_list = [i.text for i in data_info]\n",
    "            \n",
    "            #Comic list link data\n",
    "            link_list = [base_link + i['href'] for i in data_piece.find_all(\"a\")]\n",
    "            \n",
    "            #Comic details\n",
    "            req_piece = requests.get(link_list[0], headers=headers)\n",
    "            soup_piece = BeautifulSoup(req_piece.text, 'html.parser')\n",
    "            \n",
    "            series_img = soup_piece.find(\"div\", {\"id\":\"series_cover\"})\n",
    "            if series_img == None:\n",
    "                series_img = None\n",
    "            else:\n",
    "                series_img = series_img.find(\"img\")\n",
    "                if series_img == None:\n",
    "                    series_img = None\n",
    "                else:\n",
    "                    series_img = series_img['src']\n",
    "            \n",
    "            #details = soup_piece.find(\"div\", {\"id\":\"series_data\"}).find(\"dl\").find_all(\"dd\", {\"id\":\"series_format\"})\n",
    "            #print(details)# https://stackoverflow.com/questions/32475700/using-beautifulsoup-to-extract-specific-dl-and-dd-list-elements\n",
    "            \n",
    "            datas.append(data_info_list+link_list+[series_img])\n",
    "    print(len(datas), len(columns_name))\n",
    "    return columns_name, datas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    marvel_page_number = get_page_number(marvel_id)\n",
    "    columns_name, datas = scrap_comic_details(marvel_page_number)\n",
    "    \n",
    "    df_comic_list = pd.DataFrame(datas, columns=columns_name).replace({None: np.nan})\n",
    "    df_comic_list.to_csv(\"./data/comic_list.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8175b539d6487f01e9c3def2550f8b7f598099d89804d2727cf52d30e51749b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
